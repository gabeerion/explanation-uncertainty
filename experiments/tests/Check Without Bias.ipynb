{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution CIs for Integrated Gradients\n",
    "\n",
    "(Average absolute) integrated gradients, designed specifically for the linear setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from uncertainty.bootstrapCoefficients import bootstrapCis\n",
    "from uncertainty.analyticLinearRegressionCIs import analyticLinearCis\n",
    "from uncertainty.DataGeneration import default_data, linearRegression_normal\n",
    "from uncertainty.glrtTorch import glrtTorchCis, MSE\n",
    "from uncertainty.torch_linear import TorchLinear\n",
    "from uncertainty.glrt_stat import bootstrapGLRTcis\n",
    "from uncertainty.IG_linearModels import integratedGradients_Linear, bootstrapIntegratedGradients_Linear, integratedGradients_LinearAnalytical\n",
    "from attributionpriors.pytorch_ops import ExpectedGradientsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = default_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test analytical and bootstrap IG CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.89608084 1.07997608]\n",
      "Integrated gradients: [0.80678129 0.88687844]\n",
      "Bootstrapping\n",
      "Lower bounds: [0.64682205 0.7488702 ] \n",
      "Upper bounds: [0.93818827 1.0281889 ]\n",
      "Analytical\n",
      "Lower bounds: [0.66930992 0.75537646] \n",
      "Upper bounds: [0.94425266 1.01838043]\n"
     ]
    }
   ],
   "source": [
    "# Sklearn Linear Regression\n",
    "LR = LinearRegression(fit_intercept=False)\n",
    "LR.fit(X, y)\n",
    "print(\"Coefficients:\", LR.coef_)\n",
    "print(\"Integrated gradients:\", integratedGradients_Linear(LR.coef_, X))\n",
    "\n",
    "print(\"Bootstrapping\")\n",
    "lcb_LR, ucb_LR = bootstrapIntegratedGradients_Linear(LinearRegression, X, y, alpha=0.05, replicates=1000)\n",
    "print(\"Lower bounds:\", lcb_LR, \"\\nUpper bounds:\", ucb_LR)\n",
    "\n",
    "print(\"Analytical\")\n",
    "lcb_LR_a, ucb_LR_a = integratedGradients_LinearAnalytical(LR, X, y, alpha=0.05)\n",
    "print(\"Lower bounds:\", lcb_LR_a, \"\\nUpper bounds:\", ucb_LR_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.8960828 1.0799739]\n",
      "Integrated gradients: [0.80678307 0.88687669]\n",
      "Bootstrapping\n",
      "Lower bounds: [0.66413767 0.76167205] \n",
      "Upper bounds: [0.93133911 1.01799339]\n",
      "Analytical\n",
      "Lower bounds: [0.6693117 0.7553747] \n",
      "Upper bounds: [0.94425444 1.01837867]\n"
     ]
    }
   ],
   "source": [
    "# Torch Linear Regression\n",
    "TL = TorchLinear(lr=0.3,max_iter=30,fit_intercept=False)\n",
    "TL.fit(X,y)\n",
    "\n",
    "print(\"Coefficients:\", TL.coef_)\n",
    "print(\"Integrated gradients:\", integratedGradients_Linear(TL.coef_, X))\n",
    "\n",
    "# Takes ~4min\n",
    "print(\"Bootstrapping\")\n",
    "lcb_TL, ucb_TL = bootstrapIntegratedGradients_Linear(lambda:TorchLinear(lr=0.3,max_iter=30), X=X, y=y, alpha=0.05, replicates=1000)\n",
    "print(\"Lower bounds:\", lcb_TL, \"\\nUpper bounds:\", ucb_TL)\n",
    "\n",
    "print(\"Analytical\")\n",
    "lcb_TL_a, ucb_TL_a = integratedGradients_LinearAnalytical(TL, X, y, alpha=0.05)\n",
    "print(\"Lower bounds:\", lcb_TL_a, \"\\nUpper bounds:\", ucb_TL_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch IG: [0.8067829 0.8868767]\n"
     ]
    }
   ],
   "source": [
    "# Check that Torch IG calculation gives same result as analytic\n",
    "Rtorch = torch.ones_like(torch.Tensor(X))*X.mean(0).reshape(1,-1)\n",
    "Rset = torch.utils.data.TensorDataset(Rtorch)\n",
    "EGM = ExpectedGradientsModel(TL.model,Rset,k=10,random_alpha=False,scale_by_inputs=True)\n",
    "preds,igs = EGM(torch.Tensor(X),shap_values=True)\n",
    "print(\"Torch IG:\", igs.abs().mean(0).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if Torch GLRT matches analytic/bootstrap\n",
    "We get GLRT CIs for the coefs, then the attributions. We then manually check ***the upper bound of each answer for the (value/attribution) of coefficient 0*** by finding the model parameters that gave this value, checking that the MSE is within the GLRT bounds, and then checking that the parameters do include the coefficient or IG value reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytic\n",
      "Lower bounds: [0.74339329 0.91984252] \n",
      "Upper bounds: [1.0487684  1.24010963]\n",
      "GLRT\n",
      "Lower bounds: [0.53877687 0.68697059] \n",
      "Upper bounds: [1.25338912 1.47298121]\n"
     ]
    }
   ],
   "source": [
    "# GLRT method with Torch model (coefs)\n",
    "TL = TorchLinear(lr=0.3,max_iter=30,fit_intercept=False)\n",
    "TL.fit(X,y)\n",
    "print(\"Analytic\")\n",
    "lcb_TL_a, ucb_TL_a = analyticLinearCis(LR, X, y, alpha=0.05)\n",
    "print(\"Lower bounds:\", lcb_TL_a, \"\\nUpper bounds:\", ucb_TL_a)\n",
    "\n",
    "print(\"GLRT\")\n",
    "lcb_GLRT, ucb_GLRT, lcb_Results, ucb_Results, lcb_Torch, ucb_Torch = glrtTorchCis(\n",
    "    lambda:TorchLinear(lr=0.3,max_iter=100,fit_intercept=False), X=X, y=y, citype='coefs', alpha=0.05,search_kwargs={'lmbds':np.logspace(-10,10,101)},fit_kwargs={'lr':0.3,'max_iter':30})\n",
    "print(\"Lower bounds:\", lcb_GLRT, \"\\nUpper bounds:\", ucb_GLRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch attribution search found the following model\n",
      "maximizing coefficient value for feature 0:\n",
      "Coefs: [1.2533891  0.88666147], Bias: 0.0\n",
      "Corresponding Analytic IG: [1.12848177 0.72812811]\n",
      "Model MSE 1.161 < MSE UCB 1.246\n"
     ]
    }
   ],
   "source": [
    "# Manually check Torch GLRT (coefs) answer\n",
    "lcb_MSE, ucb_MSE = lcb_Torch, ucb_Torch#bootstrapGLRTcis(lambda:TorchLinear(lr=0.3,max_iter=100), X, y, lambda x,y: np.mean((x-y)**2), alpha=0.05)\n",
    "(mses, attributions, coefs, biases) = ucb_Results[0]\n",
    "valid_inds = mses<=ucb_MSE\n",
    "valid_attribs, valid_coefs, valid_biases = attributions[valid_inds], coefs[valid_inds], biases[valid_inds]\n",
    "max_ind = np.argmax(valid_attribs)\n",
    "max_coef, max_bias = valid_coefs[max_ind], valid_biases[max_ind]\n",
    "print(\"Torch attribution search found the following model\\nmaximizing coefficient value for feature 0:\")\n",
    "print(f'Coefs: {max_coef}, Bias: {max_bias}')\n",
    "print(f'Corresponding Analytic IG: {integratedGradients_Linear(max_coef,X)}')\n",
    "print(f'Model MSE {MSE(y,X@max_coef+max_bias):.3f} < MSE UCB {ucb_MSE:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytic\n",
      "Lower bounds: [0.71083121 0.67245359] \n",
      "Upper bounds: [0.99350252 0.95242894]\n",
      "GLRT\n",
      "Lower bounds: [0.35878703 0.32831344] \n",
      "Upper bounds: [1.34556675 1.29657757]\n"
     ]
    }
   ],
   "source": [
    "# GLRT method with Torch model (attribs)\n",
    "TL = TorchLinear(lr=0.3,max_iter=30)\n",
    "TL.fit(X,y)\n",
    "print(\"Analytic\")\n",
    "lcb_TL_a, ucb_TL_a = integratedGradients_LinearAnalytical(LR, X, y, alpha=0.05)\n",
    "print(\"Lower bounds:\", lcb_TL_a, \"\\nUpper bounds:\", ucb_TL_a)\n",
    "print(\"GLRT\")\n",
    "lcb_GLRT, ucb_GLRT, lcb_Results, ucb_Results, lcb_Torch, ucb_Torch = glrtTorchCis(lambda:TorchLinear(lr=0.3,max_iter=100), X=X, y=y, alpha=0.05,search_kwargs={'lmbds':np.logspace(-10,10,101)},fit_kwargs={'lr':0.3,'max_iter':30})\n",
    "print(\"Lower bounds:\", lcb_GLRT, \"\\nUpper bounds:\", ucb_GLRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch attribution search found the following model\n",
      "maximizing attribution value for feature 0:\n",
      "Coefs: [1.4582624  0.67052597], Bias: 0.004671680741012096\n",
      "Corresponding Analytic IG: [1.34556671 0.53622409]\n",
      "Model MSE 1.277 < MSE UCB 1.282\n"
     ]
    }
   ],
   "source": [
    "# Manually check Torch GLRT (attribs) answer\n",
    "lcb_MSE, ucb_MSE = lcb_Torch, ucb_Torch#bootstrapGLRTcis(lambda:TorchLinear(lr=0.3,max_iter=100), X, y, lambda x,y: np.mean((x-y)**2), alpha=0.05)\n",
    "(mses, attributions, coefs, biases) = ucb_Results[0]\n",
    "valid_inds = mses<=ucb_MSE\n",
    "valid_attribs, valid_coefs, valid_biases = attributions[valid_inds], coefs[valid_inds], biases[valid_inds]\n",
    "max_ind = np.argmax(valid_attribs)\n",
    "max_coef, max_bias = valid_coefs[max_ind], valid_biases[max_ind]\n",
    "print(\"Torch attribution search found the following model\\nmaximizing attribution value for feature 0:\")\n",
    "print(f'Coefs: {max_coef}, Bias: {max_bias}')\n",
    "print(f'Corresponding Analytic IG: {integratedGradients_Linear(max_coef,X)}')\n",
    "print(f'Model MSE {MSE(y,X@max_coef+max_bias):.3f} < MSE UCB {ucb_MSE:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an example where the coefficient CI's cross zero:\n",
    "X, y = linearRegression_normal(beta=np.array([0, 1]).T,\n",
    "                               cov=np.array([[1, 0.5],[0.5, 1]]),\n",
    "                               sigma=1,\n",
    "                               n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.03031536 0.97920903]\n",
      "Coefficient CI's (analytical) \n",
      "Lower bounds: [-0.16828497  0.79755857] \n",
      "Upper bounds: [0.21636452 1.15397532]\n",
      "Integrated gradients: [0.02422638 0.81392509]\n",
      "Bootstrapping\n",
      "Lower bounds: [0.00322201 0.6459373 ] \n",
      "Upper bounds: [0.1917331  0.96169281]\n",
      "Analytical\n",
      "Lower bounds: [0.         0.66902844] \n",
      "Upper bounds: [0.16020267 0.95882174]\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X, y)\n",
    "print(\"Coefficients:\", LR.coef_)\n",
    "lcb_LR_coef, ucb_LR_coef = bootstrapCis(LinearRegression, X, y, alpha=0.05, replicates=1000)\n",
    "print(\"Coefficient CI's (analytical)\", \"\\nLower bounds:\", lcb_LR_coef, \"\\nUpper bounds:\", ucb_LR_coef)\n",
    "\n",
    "print(\"Integrated gradients:\", integratedGradients_Linear(LR.coef_, X))\n",
    "\n",
    "print(\"Bootstrapping\")\n",
    "lcb_LR, ucb_LR = bootstrapIntegratedGradients_Linear(LinearRegression, X, y, alpha=0.05, replicates=1000)\n",
    "print(\"Lower bounds:\", lcb_LR, \"\\nUpper bounds:\", ucb_LR)\n",
    "\n",
    "print(\"Analytical\")\n",
    "lcb_LR_a, ucb_LR_a = integratedGradients_LinearAnalytical(LR, X, y, alpha=0.05)\n",
    "print(\"Lower bounds:\", lcb_LR_a, \"\\nUpper bounds:\", ucb_LR_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And an example where the coefficient CI's are negative:\n",
    "X, y = linearRegression_normal(beta=np.array([-1, 1]).T,\n",
    "                               cov=np.array([[1, 0.5],[0.5, 1]]),\n",
    "                               sigma=1,\n",
    "                               n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.00387075  1.0247226 ]\n",
      "Coefficient CI's (analytical) \n",
      "Lower bounds: [-1.16141947  0.86636686] \n",
      "Upper bounds: [-0.84127545  1.20309793]\n",
      "Integrated gradients: [0.77268915 0.9136594 ]\n",
      "Bootstrapping\n",
      "Lower bounds: [0.64189068 0.76713352] \n",
      "Upper bounds: [0.90386435 1.0611927 ]\n",
      "Analytical\n",
      "Lower bounds: [0.63028801 0.77010731] \n",
      "Upper bounds: [0.9150903  1.05721149]\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X, y)\n",
    "print(\"Coefficients:\", LR.coef_)\n",
    "lcb_LR_coef, ucb_LR_coef = bootstrapCis(LinearRegression, X, y, alpha=0.05, replicates=1000)\n",
    "print(\"Coefficient CI's (analytical)\", \"\\nLower bounds:\", lcb_LR_coef, \"\\nUpper bounds:\", ucb_LR_coef)\n",
    "\n",
    "print(\"Integrated gradients:\", integratedGradients_Linear(LR.coef_, X))\n",
    "\n",
    "print(\"Bootstrapping\")\n",
    "lcb_LR, ucb_LR = bootstrapIntegratedGradients_Linear(LinearRegression, X, y, alpha=0.05, replicates=1000)\n",
    "print(\"Lower bounds:\", lcb_LR, \"\\nUpper bounds:\", ucb_LR)\n",
    "\n",
    "print(\"Analytical\")\n",
    "lcb_LR_a, ucb_LR_a = integratedGradients_LinearAnalytical(LR, X, y, alpha=0.05)\n",
    "print(\"Lower bounds:\", lcb_LR_a, \"\\nUpper bounds:\", ucb_LR_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
